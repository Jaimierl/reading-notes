# Linear Regressions

This topic matters in relation to what we are studying in this module as we study and model linear regressions.

Linear regressions are predictive analysis tools that aim to predict outcomes related to independent(or explanatory) and dependent (or response) variables. This is like predicting the grade you feel like you will get on a test depending on how much you studied and how comfortable you feel with the material. Another example of this is predicting the highest or lowest overall grade you may get in a class based on the grades you have received in the class so far. 

There is the independent variable (ie. how much you studied) and the dependent variable (ie. your grade on the test). There are many types of regression analyses depending on the input variables. Simple linear regression has one independent and one dependent variable. Multiple linear regression has two independent variables (such as adding how closely the teacher tests on the materials presented in class).

Regressions can be graphed by showing a scatter plot of the measured data and applying a line of best fit. Then the response variable can be predicted for a certain amount of the explanatory variable (plus an error coefficient). Linear progression lines of best fit can be modeled in Python using scikit-Learn. Validation measures the accuracy of the lines of best fit by using sample data.

[Reading Notes Home Page](README.md)